# D:\github\1968_SMART_CHAT_BACK\process_pdf.py
import os
import uuid
import traceback
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv(filename=".env", usecwd=True), override=False)

import uvicorn
from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import json, logging, asyncio, time, re
from functools import lru_cache
import requests
from datetime import datetime, timezone, timedelta

# === LangChain / OpenAIï¼ˆæ–°ç‰ˆåŒ¯å…¥è·¯å¾‘ï¼‰ ===
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.messages import SystemMessage, HumanMessage

# === DB ===
import pymysql

# === è·¯ç”± / æœå‹™ ===
from core.faq_gate import faq_gate
from services.faq_service import answer_from_docs
from core.intent_router import route_question
from core.geocoding import geocode
from core.config import SLA_SEC
from services.incidents_service import query_incidents_by_filters
from services.alt_routes_service import summarize_alt_routes
from services.shoulder_service import summarize_scs
from services.parking_service import summarize_parking


# === Prompts / æ¨™é¡Œï¼ˆä¸ä½¿ç”¨ QA_PREFIXï¼Œé¿å…å‡ºç¾ ğŸ“˜ å‰ç¶´ï¼‰ ===
from prompts.all_zh import (
    ANSWER_DISCLAIMER,
    INCIDENTS_PREFIX, ALT_ROUTES_PREFIX, SCS_PREFIX, PARKING_PREFIX, WEATHER_PREFIX,
    SOFT_REFUSAL,
)

REFUSAL_ENABLED = (os.getenv("REFUSAL_ENABLED", "false").lower() == "true")

# =============================================================================
# FastAPI
# =============================================================================
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
    # è®“å‰ç«¯ F12 â†’ Network â†’ Headers çœ‹å¾—åˆ°é€™äº›æ¬„ä½
    expose_headers=["X-Route","X-Filters","X-Reason","X-Forced-QA","X-Fallback","X-Timings-ms"],
)

LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()

logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler("service.log", encoding="utf-8"),
        logging.StreamHandler()  # â† é€™è¡ŒæœƒæŠŠ log åŒæ­¥å°åˆ° console
    ]
)

# =============================================================================
# å‘é‡åº«ï¼ˆPDF å…œåº•ç”¨ï¼‰
# =============================================================================
PDF_JSON_PATH = os.getenv("PDF_JSON_PATH", os.path.join(os.getcwd(), "PDF", "all_text.json"))

embeddings = OpenAIEmbeddings()
rag_llm = ChatOpenAI(model=os.getenv("RAG_MODEL", "gpt-4o-mini"), temperature=0)
qa_llm  = ChatOpenAI(model=os.getenv("QA_MODEL",  "gpt-4o-mini"), temperature=0)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)

def build_vector_from_json(json_path):
    with open(json_path, "r", encoding="utf-8") as f:
        pages = json.load(f)
    documents = []
    for idx, page_text in enumerate(pages):
        if not page_text:
            continue
        chunks = text_splitter.split_text(page_text)
        for chunk in chunks:
            documents.append(Document(page_content=chunk, metadata={"page": idx + 1}))
    return FAISS.from_documents(documents, embeddings)

FAISS_INDEX_DIR = "faiss_index"
FAISS_INDEX_FILE = os.path.join(FAISS_INDEX_DIR, "index.faiss")
if os.path.exists(FAISS_INDEX_FILE):
    vector_store = FAISS.load_local(FAISS_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
else:
    vector_store = build_vector_from_json(PDF_JSON_PATH)
    vector_store.save_local(FAISS_INDEX_DIR)

retriever = vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 5, "lambda_mult": 0.3})

# â€”â€” RAGï¼šä¸­ç«‹ç‰ˆ Promptï¼ˆä¸åŒ…å«ä»»ä½•å©‰æ‹’æŒ‡ç¤ºï¼‰â€”â€”
RAG_PROMPT_NEUTRAL = (
    "è«‹åªæ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”ï¼Œå›è¦†å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
    "è‹¥ç„¡æ³•åœ¨å…§å®¹ä¸­ç›´æ¥æ‰¾åˆ°ç­”æ¡ˆï¼Œè«‹ç°¡çŸ­æä¾›å¯è¡Œçš„æŸ¥è©¢æ–¹å‘æˆ–éœ€è¦è£œå……çš„è³‡è¨Šï¼Œä¸è¦å©‰æ‹’ã€‚\n"
    "ã€å…§å®¹ã€‘\n{context}\n\nã€å•é¡Œã€‘\n{question}"
)

def rag_answer(question: str) -> str:
    try:
        # denseï¼ˆFAISSï¼‰
        try:
            # æ–°ç‰ˆ retriever ç”¨ invokeï¼›ä¸æ”¯æ´å°±å›é€€èˆŠæ³•
            docs_dense = retriever.invoke(question) if hasattr(retriever, "invoke") else retriever.get_relevant_documents(question)
        except Exception:
            docs_dense = []
        faiss_docs = (docs_dense or [])[:4]

        # sparseï¼ˆBM25 å¯é¸ï¼‰
        bm25_docs = []
        try:
            from langchain_community.retrievers import BM25Retriever
            bm25 = BM25Retriever.from_texts([d.page_content for d in vector_store.docstore._dict.values()])
            bm25.k = 4
            bm25_docs = bm25.get_relevant_documents(question)
        except Exception as e:
            logging.error(f"[RAG] BM25 ç•¥éï¼š{type(e).__name__}: {e}")

        # union + å»é‡
        seen, docs = set(), []
        for arr in (faiss_docs, bm25_docs):
            for d in arr:
                key = (d.metadata.get("page"), d.page_content[:64])
                if key not in seen:
                    seen.add(key); docs.append(d)

        context = "\n\n".join([f"[ç¬¬{d.metadata.get('page')}é ]\n{d.page_content}" for d in docs[:6]])
        prompt_text = RAG_PROMPT_NEUTRAL.format(context=context, question=question)
        resp = rag_llm.invoke([HumanMessage(content=prompt_text)])
        return (resp.content or "").strip()
    except Exception as e:
        logging.error(f"[RAG] {type(e).__name__}: {e}")
        return ""

# â€”â€” åµæ¸¬ã€ŒRAG å›è¦†ç„¡å¹«åŠ©ã€ï¼šå¤ªçŸ­æˆ–å¸¸è¦‹æ‰“æ§/æŒ‡å¼•å¥å‹ï¼Œå°±è¦–ç‚ºç„¡å¹«åŠ© â€”â€” 
_UNHELPFUL_PAT = re.compile(
    r"(ç„¡æ³•.*æŸ¥è©¢|æ‰¾ä¸åˆ°|ç„¡æ³•ç›´æ¥|è³‡æ–™ä¸è¶³|æœªæä¾›|æ²’æœ‰æä¾›|ç„¡ç›¸é—œè³‡æ–™|"
    r"è«‹.*ä½¿ç”¨.*APP|å»ºè­°.*æŸ¥è©¢|è«‹.*è‡³.*å®˜æ–¹ç¶²ç«™|åƒ…ä¾›åƒè€ƒ)",
    re.I
)

def _rag_is_unhelpful(ans: str) -> bool:
    if not ans:
        return True
    s = ans.strip()
    # â˜… æ”¾å¯¬ï¼šçŸ­å¥ä½†ä¸å«æ‰“æ§è©ï¼Œå°±ç•¶ä½œæœ‰å¹«åŠ©ï¼ˆFAQ å¸¸è¦‹ï¼‰
    if len(s) < 50 and not _UNHELPFUL_PAT.search(s):
        return False
    return bool(_UNHELPFUL_PAT.search(s))

def qa_free_answer(question: str) -> str:
    msgs = [
        SystemMessage(content=(
            "ä½ æ˜¯å°ç£é«˜é€Ÿå…¬è·¯/äº¤é€šè³‡è¨ŠåŠ©ç†ã€‚"
            "å°æ–¼ã€æœ€è¿‘çš„äº¤æµé“ã€ã€é™„è¿‘çš„ä¼‘æ¯ç«™ã€ã€æœå‹™å€æœ‰å“ªäº›è¨­æ–½ã€ç­‰æ²’æœ‰å³æ™‚ API çš„å•é¡Œï¼Œ"
            "è«‹ç”¨å¸¸è­˜èˆ‡åœ°ç†çŸ¥è­˜çµ¦å‡ºå¯è¡Œå»ºè­°æˆ–æŸ¥è©¢æ­¥é©Ÿï¼Œä¸¦å‘ŠçŸ¥éœ€è¦çš„è£œå……è³‡è¨Šï¼ˆå¦‚åœ‹é“è™Ÿã€æ–¹å‘ã€é‡Œç¨‹ã€æœå‹™å€åç¨±ï¼‰ã€‚"
            "å›è¦†ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€ç°¡æ½”æ‰¼è¦ï¼›ä¸ç¢ºå®šçš„è³‡è¨Šéœ€æ¨™ç¤ºç‚ºå»ºè­°æˆ–éœ€æŸ¥è­‰ã€‚"
            "è‹¥åˆ¤æ–·å•é¡Œèˆ‡å°ç£äº¤é€š/æ°£è±¡ç„¡é—œï¼Œè«‹å›è¦†ï¼š"
            "ã€Œæˆ‘ä¸»è¦å”åŠ©å°ç£çš„äº¤é€š/æ°£è±¡æŸ¥è©¢ï¼ˆåœ‹é“è·¯æ³ã€æ›¿ä»£é“è·¯ã€æœå‹™å€ã€å¤©æ°£ï¼‰ã€‚"
            "è‹¥å•é¡Œä¸åœ¨é€™äº›ç¯„åœï¼Œå¯èƒ½ç„¡æ³•å®Œæ•´å›ç­”ï¼›ä¹Ÿæ­¡è¿å‘Šè¨´æˆ‘è¦æŸ¥çš„è·¯æ®µ/äº¤æµé“æˆ–åœ°é»ï¼Œæˆ‘æœƒç›´æ¥å¹«ä½ æŸ¥ã€‚ã€"
        )),
        HumanMessage(content=question[:1000])
    ]
    try:
        resp = qa_llm.invoke(msgs)
        return (resp.content or "").strip()
    except Exception as e:
        logging.error(f"[QA_FREE] {type(e).__name__}: {e}")
        return ""

# =============================================================================
# å…±ç”¨ï¼šå³æ™‚å¤©æ°£ï¼ˆOpen-Meteoï¼‰
# =============================================================================
@lru_cache(maxsize=256)
def openmeteo_current(lat, lon):
    try:
        js = requests.get(
            "https://api.open-meteo.com/v1/forecast",
            params={
                "latitude": round(float(lat), 2),
                "longitude": round(float(lon), 2),
                "current": "temperature_2m,precipitation,weather_code,wind_speed_10m",
                "timezone": "Asia/Taipei",
            },
            timeout=6
        ).json()
        cur = js.get("current", {})
        return {
            "temp_c": cur.get("temperature_2m"),
            "wind_ms": cur.get("wind_speed_10m"),
            "rain_mm": cur.get("precipitation", 0),
        }
    except Exception:
        return {}

def _iso_ts_taipei() -> str:
    tz = timezone(timedelta(hours=8))
    s = datetime.now(tz).strftime("%Y-%m-%dT%H:%M%z")  # e.g., 2025-11-12T16:18+0800
    return f"{s[:-2]}:{s[-2:]}"  # â†’ 2025-11-12T16:18+08:00

def add_disclaimer(ans: str) -> str:
    """åœ¨ç­”æ¡ˆæœ€å¾ŒåŠ ä¸Š Disclaimerï¼ˆç´”æ–‡å­—ï¼Œä¸å«æ™‚é–“ã€ä¸å« HTML æ¨™ç±¤ï¼‰"""
    base = (ans or "").rstrip()

    # å¦‚æœæœ¬ä¾†å­—ä¸²è£¡å°±å·²ç¶“æœ‰ disclaimer å°±ä¸è¦é‡è¤‡åŠ 
    if ANSWER_DISCLAIMER in base:
        return base

    # å’Œä¸»å…§å®¹ç”¨æ›è¡Œéš”é–‹
    if base:
        return f"{base}\n{ANSWER_DISCLAIMER}"
    else:
        return ANSWER_DISCLAIMER

# â€”â€” åªé¡¯ç¤ºå°ç£ç¸£å¸‚åç¨±ç”¨çš„å·¥å…· â€”â€”
_TW_CITY_LIST = [
    "å°åŒ—å¸‚","è‡ºåŒ—å¸‚","æ–°åŒ—å¸‚","æ¡ƒåœ’å¸‚","å°ä¸­å¸‚","è‡ºä¸­å¸‚","å°å—å¸‚","è‡ºå—å¸‚","é«˜é›„å¸‚",
    "åŸºéš†å¸‚","æ–°ç«¹å¸‚","å˜‰ç¾©å¸‚",
    "æ–°ç«¹ç¸£","è‹—æ —ç¸£","å½°åŒ–ç¸£","å—æŠ•ç¸£","é›²æ—ç¸£","å˜‰ç¾©ç¸£","å±æ±ç¸£",
    "å®œè˜­ç¸£","èŠ±è“®ç¸£","å°æ±ç¸£","è‡ºæ±ç¸£","æ¾æ¹–ç¸£","é‡‘é–€ç¸£","é€£æ±Ÿç¸£"
]
_CITY_REGEX = re.compile(r"([^\d\s]{1,6}[å¸‚ç¸£])")  # æ‰¾ç¬¬ä¸€å€‹ä»¥ å¸‚/ç¸£ çµå°¾çš„ç‰‡æ®µ

def _only_city_name(label: str, fallback_text: str = "") -> str:
    """å¾ geocode çš„ label æŠ“å‡ºç¸£å¸‚åï¼›å–ä¸åˆ°å°±ç”¨å‚™æ´å­—ä¸²ï¼›çµ±ä¸€ã€è‡ºã€ç‚ºã€å°ã€ã€‚"""
    x = (label or "") + " " + (fallback_text or "")
    for n in _TW_CITY_LIST:
        if n in x:
            return n.replace("è‡º", "å°")
    m = _CITY_REGEX.search(x)
    if m:
        return m.group(1).replace("è‡º", "å°")
    x = (fallback_text or label or "").replace("è‡º", "å°")
    m2 = _CITY_REGEX.search(x)
    return (m2.group(1) if m2 else x)

# =============================================================================
# å¼·åˆ¶ QAï¼ˆæ²’æœ‰ API çš„éœ€æ±‚ï¼‰
# =============================================================================
_QA_HINT = re.compile(
    r"(æœå‹™å€|ä¼‘æ¯ç«™|è¨­æ–½|å»æ‰€|é¤å»³|é¤é£²|åŠ æ²¹|å……é›»|è¶…å•†|å“ºä¹³å®¤|"
    r"æœ€è¿‘çš„?äº¤æµé“|æœ€è¿‘äº¤æµé“|é™„è¿‘äº¤æµé“|å…¬é‡Œè™•|é‡Œç¨‹è™•|å¹¾K)",
    re.I
)

def _should_force_qa(q: str, route: str, filters: dict) -> bool:
    if route == "qa":
        return False
    x = q or ""
    if _QA_HINT.search(x):
        # è‹¥è¢«åˆ¤åˆ° incidents ä½†æ¢ä»¶å¹¾ä¹ç©ºï¼Œè¦–ç‚ºèª¤åˆ¤ â†’ æ”¹ QA
        if route == "incidents":
            sig = any([
                (filters.get("road")), (filters.get("direction")),
                (filters.get("exit")), (filters.get("places"))
            ])
            return not sig
        return True
    # åŒ…å«ã€Œæœå‹™å€ã€ä½†ä¸æ˜¯å•åœè»Š/è»Šä½ â†’ QA
    if ("æœå‹™å€" in x) and not any(k in x for k in ["åœè»Š", "è»Šä½"]):
        return True
    return False

# =============================================================================
# å¾Œç½®ä¿éšªè·¯ç”±ï¼ˆé—œéµå­—æ¥µç°¡è£œæ•‘ï¼šä¿è­‰ parking / incidents / weather èƒ½å‘½ä¸­ï¼‰
# =============================================================================
_ROAD_PAT = re.compile(
    r"(ä¸­å±±é«˜|åŒ—äºŒé«˜|äºŒé«˜|ä¸€é«˜|ä¸‰é«˜|åŒ—å®œé«˜|"
    r"åœ‹é“?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+è™Ÿ?|"
    r"åœ‹?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|"
    r"å°?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç·š|"
    r"çœé“?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+è™Ÿ)",
    re.I
)

_DIR_PAT  = re.compile(
    r"(å—ä¸‹|åŒ—ä¸Š|æ±è¡Œ|è¥¿è¡Œ|é †å‘|é€†å‘|å¾€å—|å¾€åŒ—|å¾€æ±|å¾€è¥¿|å—å‘|åŒ—å‘|æ±å‘|è¥¿å‘)"
)

_PARKING_PAT = re.compile(
    r"(?P<name>[\u4e00-\u9fa5]{2,8}?)(?:æœå‹™å€)?"
    r"(?:çš„|ç›®å‰|ç¾åœ¨|é‚„|æ˜¯å¦|æœ‰æ²’æœ‰|æœ‰ç„¡|æŸ¥|çœ‹)?"
    r"(?:.*?)(?:è»Šä½|åœè»Š|åœè»Šä½|åœè»Šå ´|ç©ºä½|å‰©é¤˜|å¯ç”¨)",
    re.I
)

def _sanitize_sa_name(name: str) -> str:
    if not name:
        return ""
    n = re.sub(r"(æœå‹™å€)?(çš„|ç›®å‰|ç¾åœ¨|é‚„|æ˜¯å¦|æœ‰æ²’æœ‰|æœ‰ç„¡)$", "", name.strip())
    n = n.replace("æœå‹™å€", "")
    return n

# å°‡å…¨å½¢ã€ä¸­æ–‡æ•¸å­—è½‰æˆå¯è¾¨è­˜çš„åœ‹é“/å°ç·šå­—ä¸²
def _normalize_digits(s: str) -> str:
    # å…¨å½¢â†’åŠå½¢
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
    # ä¸­æ–‡æ•¸å­—ï¼ˆå¸¸ç”¨åˆ° 1~10ï¼‰
    s = (s.replace("ä¸€", "1").replace("äºŒ", "2").replace("ä¸‰", "3")
           .replace("å››", "4").replace("äº”", "5").replace("å…­", "6")
           .replace("ä¸ƒ", "7").replace("å…«", "8").replace("ä¹", "9")
           .replace("å", "10"))
    return s

def _normalize_road_name(expr: str) -> str:
    x = _normalize_digits(expr.replace(" ", ""))
    x = x.replace("è‡º", "å°")

    # å…ˆæŠŠå¯èƒ½é»åœ¨ä¸€èµ·çš„æ–¹å‘å­—å°¾å»æ‰ï¼ˆä¾‹ï¼šåœ‹ä¸€å—ä¸‹ â†’ åœ‹ä¸€ï¼‰
    x = re.sub(r"(å—ä¸‹|åŒ—ä¸Š|æ±è¡Œ|è¥¿è¡Œ|å—å‘|åŒ—å‘|æ±å‘|è¥¿å‘|å¾€å—|å¾€åŒ—|å¾€æ±|å¾€è¥¿)$", "", x)

    # åˆ¥åæ˜ å°„
    if "ä¸­å±±é«˜" in x:
        return "åœ‹é“1è™Ÿ"
    if "åŒ—äºŒé«˜" in x or x == "äºŒé«˜":
        return "åœ‹é“3è™Ÿ"
    if "ä¸€é«˜" in x:
        return "åœ‹é“1è™Ÿ"
    if "ä¸‰é«˜" in x:
        return "åœ‹é“3è™Ÿ"
    if "åŒ—å®œé«˜" in x:
        return "åœ‹é“5è™Ÿ"

    # çµ±ä¸€å¸¸è¦‹ç¸®å¯«ï¼šåœ‹1â†’åœ‹é“1è™Ÿã€åœ‹3â†’åœ‹é“3è™Ÿï¼ˆä¸­æ–‡æ•¸å­—å·²è½‰æˆé˜¿æ‹‰ä¼¯æ•¸å­—ï¼‰
    m = re.search(r"^åœ‹?é“?(\d{1,2})è™Ÿ?$", x)
    if m:
        return f"åœ‹é“{m.group(1)}è™Ÿ"

    # å°ç·š/çœé“ä¿æŒåŸæ¨£ï¼ˆexï¼šå°74ç·šï¼‰
    m2 = re.search(r"^(å°|çœé“)(\d{1,3})(è™Ÿ|ç·š)?$", x)
    if m2:
        prefix = "å°" if m2.group(1).startswith("å°") else "çœé“"
        suf = "ç·š" if (m2.group(3) or "") == "ç·š" else "è™Ÿ"
        return f"{prefix}{m2.group(2)}{suf}"

    return expr  # è¬ä¸€æŠ“ä¸æº–ï¼Œå°±åŸæ¨£å›å‚³

def _fallback_route(q: str, route: str, filters: dict):
    x = q or ""

    # parkingï¼šå‘½ä¸­ã€ŒOOæœå‹™å€ + è»Šä½/åœè»Š/ç©ºä½â€¦ã€â†’ ç›´æ¥å°åˆ° parking
    m = _PARKING_PAT.search(x)
    if m:
        raw = (m.group("name") or "").strip()
        base = _sanitize_sa_name(raw)
        if base:
            pname = base + "æœå‹™å€"
            new_filters = dict(filters or {})
            new_filters.setdefault("parking_name", pname)
            # è‹¥åŸæœ¬ route ä¸æ˜¯ parkingï¼Œå°±å¼·åˆ¶æ”¹æˆ parking
            if route != "parking":
                return "parking", new_filters, "fallback_parking"
            else:
                return route, new_filters, "fallback_parking_enhance"

    # weatherï¼šçœ‹åˆ°ã€Œå¤©æ°£/æ°£è±¡ã€â†’ å° weather
    if ("å¤©æ°£" in x or "æ°£è±¡" in x):
        place = re.sub(r"(ç¾åœ¨|ç›®å‰|çš„|å¤©æ°£|æ°£è±¡|å¦‚ä½•|ç‹€æ³|\?|ï¼Ÿ)", "", x).strip() or x
        new_filters = dict(filters or {})
        new_filters.setdefault("place", place)
        if route != "weather":
            return "weather", new_filters, "fallback_weather"
        else:
            return route, new_filters, "fallback_weather_enhance"

    # incidentsï¼šé“è·¯ + è·¯æ³é—œéµè© â†’ å° incidents ä¸¦è£œ road/type/direction
    if _ROAD_PAT.search(x) and re.search(r"(è·¯æ³|æ–½å·¥|äº‹æ•…|å°é–‰|å£…å¡|å›å µ)", x):
        raw = _ROAD_PAT.search(x).group(1)
        road = _normalize_road_name(raw)

        # é¡å‹åˆ¤æ–·
        itype = None
        if any(k in x for k in ["æ–½å·¥", "é¤Šè­·", "å°é–‰"]):
            itype = "construction"
        elif any(k in x for k in ["äº‹æ•…", "è»Šç¦", "æ“¦æ’", "è¿½æ’", "ç¿»è¦†"]):
            itype = "accident"
        elif any(k in x for k in ["å£…å¡", "å›å µ", "å‡ºå£", "äº¤æµé“"]):
            itype = "exit_congestion"

        # æ–¹å‘åˆ¤æ–·ï¼šæŠŠã€Œå¾€å— / å—å‘ã€éƒ½è¦ä¸€æˆã€Œå—ä¸‹ã€ä¹‹é¡
        dire = None
        mdir = _DIR_PAT.search(x)
        if mdir:
            raw_dir = mdir.group(1)
            if raw_dir in ("å—ä¸‹", "å¾€å—", "å—å‘"):
                dire = "å—ä¸‹"
            elif raw_dir in ("åŒ—ä¸Š", "å¾€åŒ—", "åŒ—å‘"):
                dire = "åŒ—ä¸Š"
            elif raw_dir in ("æ±è¡Œ", "å¾€æ±", "æ±å‘"):
                dire = "æ±è¡Œ"
            elif raw_dir in ("è¥¿è¡Œ", "å¾€è¥¿", "è¥¿å‘"):
                dire = "è¥¿è¡Œ"
            elif raw_dir in ("é †å‘", "é€†å‘"):
                dire = raw_dir

        new_filters = dict(filters or {})
        new_filters.setdefault("road", road)
        if itype and "type" not in new_filters:
            new_filters["type"] = itype
        if dire and "direction" not in new_filters:
            new_filters["direction"] = dire

        # å¦‚æœåŸæœ¬ä¸æ˜¯ incidents â†’ å¼·åˆ¶å°åˆ° incidents
        if route != "incidents":
            return "incidents", new_filters, "fallback_incidents"
        else:
            # åŸæœ¬å°±æ˜¯ incidentsï¼Œåªæ˜¯å¹«å¿™è£œ road/direction/type
            return "incidents", new_filters, "fallback_incidents_enhance"

    # æ²’å‘½ä¸­ä»»ä½•ä¿éšªè¦å‰‡ â†’ ä¸å‹•
    return route, filters, ""

def _db_ready(cfg: dict) -> bool:
    return all([
        cfg.get("host", "").strip() not in ("", "..."),
        cfg.get("user", "").strip() not in ("", "..."),
        cfg.get("password", "").strip() not in ("", "..."),
        cfg.get("database", "").strip() not in ("", "...")
    ])

def _latin1_safe(s: str, placeholder: str = "?") -> str:
    try:
        return (s or "").encode("latin-1", "replace").decode("latin-1")
    except Exception:
        return placeholder

# =============================================================================
# API
# =============================================================================
class QueryInput(BaseModel):
    question: str

@app.get("/")
async def root():
    return {"message": "1968 æ™ºèƒ½å®¢æœ APIï¼ˆLLM è·¯ç”± + RAG/QA å…œåº•ï¼‰"}

@app.post("/chatback/query/")
async def query_pdf(input: QueryInput, request: Request, response: Response):
    req_id = uuid.uuid4().hex[:8]  # â˜… Request Trace ID
    q = (input.question or "").strip()
    user_ip = request.client.host
    user_agent = request.headers.get("user-agent", "æœªçŸ¥")

    def ms_since(t0):  # å°å·¥å…·ï¼šå›å‚³ç¶“éæ¯«ç§’
        return int((time.perf_counter() - t0) * 1000)

    t0 = time.perf_counter()
    # logging.info(f"[{req_id}] === æ–°è«‹æ±‚ ===")
    # logging.info(f"[{req_id}] å•é¡Œ: {q}")
    # logging.info(f"[{req_id}] ä¾†æº: ip={user_ip} ua={user_agent}")

    answer = ""
    route = "incidents"
    filters: dict = {}
    reason = ""
    forced_qa = False
    fallback_reason = ""
    sources_used = []
    confidence = 0.0

    try:
        # 1) å”¯ä¸€è·¯ç”±ï¼šLLMï¼ˆå…ˆåˆ¤æ–·è¦èµ°å“ªç¨® API / QAï¼‰
        route, filters, reason = await route_question(q)
        confidence = float(filters.pop("_confidence", 0)) if "_confidence" in filters else 0.0
        logging.debug(f"[{req_id}] Router çµæœ route={route} conf={confidence:.2f} filters={filters} reason={reason}")

        # 1.1) å¼·åˆ¶ QAï¼ˆæœ€è¿‘äº¤æµé“/ä¼‘æ¯ç«™/æœå‹™å€è¨­æ–½ç­‰ï¼‰ï¼š
        #      â†’ åªæœ‰é€™ç¨®â€œæ²’æœ‰å³æ™‚ APIâ€çš„å•é¡Œæ‰æ”¹æˆ QA
        if _should_force_qa(q, route, filters):
            logging.debug(f"[{req_id}] è§¸ç™¼å¼·åˆ¶ QAï¼ˆforced_qaï¼‰")
            route, filters, reason = "qa", {}, f"{reason}|forced_qa"
            forced_qa = True

        # 1.2) å¾Œç½®ä¿éšªè·¯ç”±ï¼ˆparking / incidents / weather è£œæ•‘ï¼‰
        route, filters, fb = _fallback_route(q, route, filters)
        if fb:
            logging.debug(f"[{req_id}] å¾Œç½®ä¿éšªè·¯ç”±è§¸ç™¼ï¼š{fb} â†’ æ–° route={route}, filters={filters}")
            fallback_reason = fb

        # 2) åŸ·è¡Œä¸»æµç¨‹ï¼ˆä»¥ SLA é™æ™‚ï¼‰
        async def _do_main_route():
            nonlocal answer, route, filters, sources_used
            logging.debug(f"[{req_id}] åŸ·è¡Œåˆ†æ”¯ route={route} filters={filters}")

            try:
                # ä¸å…è¨±ç¡¬æ‹’çµ• â†’ å…¨éƒ¨æ”¹èµ° QA/RAG
                if (route == "refuse") and (not REFUSAL_ENABLED):
                    logging.debug(f"[{req_id}] route=refuse ä¸” REFUSAL_DISABLED â†’ æ”¹èµ° qa")
                    route = "qa"
                    filters = {}

                # ========= é€™è£¡é–‹å§‹ï¼šå„ç¨® API å„ªå…ˆ =========
                if route == "incidents":
                    res = await asyncio.get_running_loop().run_in_executor(
                        None, lambda: query_incidents_by_filters(filters, limit=5)
                    )
                    summary = (res or {}).get("summary") or "ç›®å‰æŸ¥ç„¡ç¬¦åˆæ¢ä»¶çš„äº‹ä»¶ã€‚"
                    answer = add_disclaimer(f"{INCIDENTS_PREFIX}\n{summary}")
                    sources_used = [{"api": "incidents", "ts": time.time()}]
                    return

                elif route == "alt_routes":
                    summary = await asyncio.get_running_loop().run_in_executor(None, summarize_alt_routes)
                    answer = add_disclaimer(f"{ALT_ROUTES_PREFIX}\n{summary}")
                    sources_used = [{"api": "alt_routes", "ts": time.time()}]
                    return

                elif route == "scs":
                    summary = await asyncio.get_running_loop().run_in_executor(None, summarize_scs)
                    answer = add_disclaimer(f"{SCS_PREFIX}\n{summary}")
                    sources_used = [{"api": "scs", "ts": time.time()}]
                    return

                elif route == "parking":
                    # â˜… æœå‹™å€åœè»Šä½ï¼šä¸€å®šå„ªå…ˆèµ° API
                    kw = (filters.get("parking_name") or "").strip()
                    if not kw:
                        answer = add_disclaimer("è«‹æä¾›è¦æŸ¥è©¢çš„æœå‹™å€åç¨±ï¼ˆä¾‹å¦‚ï¼šé—œè¥¿æœå‹™å€ï¼‰ã€‚")
                        sources_used = []
                        return
                    summary = await asyncio.get_running_loop().run_in_executor(
                        None, lambda: summarize_parking(keyword=kw, limit=8)
                    )
                    answer = add_disclaimer(f"{PARKING_PREFIX}\n{summary}")
                    sources_used = [{"api": "parking", "ts": time.time(), "kw": kw}]
                    return

                elif route == "weather":
                    # å¤©æ°£ â†’ Open-Meteo APIï¼ˆä¸æ˜¯ PDFï¼‰
                    place = (filters.get("place") or "").strip() or q
                    coord = await asyncio.get_running_loop().run_in_executor(None, geocode, place)
                    if coord:
                        lat, lon, label, _ = coord
                        display_name = _only_city_name(label, place)
                        weather = await asyncio.get_running_loop().run_in_executor(None, openmeteo_current, lat, lon)
                        if weather:
                            ans = (
                                f"ã€Œ{display_name}ã€ç›®å‰ï¼š"
                                f"{weather.get('temp_c', 'â€”')}Â°Cã€"
                                f"é™é›¨ {weather.get('rain_mm', 0)} mmã€"
                                f"é¢¨é€Ÿ {weather.get('wind_ms', 'â€”')} m/s"
                            )
                        else:
                            ans = "ç›®å‰ç„¡æ³•å–å¾—è©²åœ°å³æ™‚å¤©æ°£ã€‚"
                        answer = add_disclaimer(f"{WEATHER_PREFIX}{ans}")
                        sources_used = [{"api": "open-meteo", "lat": lat, "lon": lon, "ts": time.time()}]
                    else:
                        answer = add_disclaimer("ç„¡æ³•è¾¨è­˜å¤©æ°£æŸ¥è©¢åœ°é»ï¼Œè«‹æä¾›æ›´æ˜ç¢ºçš„åœ°åæˆ–åœ°å€ã€‚")
                        sources_used = []
                    return

                # ========= QA é¡ï¼šé€™è£¡æ‰æœƒç”¨åˆ° PDF / RAG =========
                elif route == "qa":
                    # 2.1) å…ˆæŸ¥ 1968_QA.pdfï¼ˆFAQï¼‰ï¼›åªåœ¨ QA é¡å•é¡Œæ™‚æ‰å•Ÿç”¨
                    hit, hit_score, top_docs = faq_gate(q)
                    logging.debug(f"[{req_id}] FAQ Gate (QA) hit={hit} score={hit_score:.2f} top_docs={len(top_docs)}")

                    if hit:
                        # PDF å„ªå…ˆæ–¼ RAG/è‡ªç”± QA
                        if top_docs:
                            pack = await asyncio.get_running_loop().run_in_executor(None, answer_from_docs, q, top_docs)
                            answer = add_disclaimer(pack["text"])
                            sources_used = pack.get("sources", [])
                        else:
                            # åƒ…è¦å‰‡å‘½ä¸­æ™‚çš„ä¿å®ˆç­”è¦†ï¼Œå¯è¦–æƒ…æ³èª¿æ•´
                            answer_text = "å¯æ–¼ 1968 APP çš„ã€Œç®¡åˆ¶æªæ–½ã€æˆ–é¦–é å…¬å‘ŠæŸ¥è©¢ç›¸é—œè³‡è¨Šã€‚"
                            answer = add_disclaimer(answer_text)
                            sources_used = [{"faq": "rule"}]
                        return

                    # 2.2) FAQ æ²’ä¸­ â†’ å†èµ° RAG + è‡ªç”± QA
                    rag_ans = rag_answer(q)
                    if rag_ans and not _rag_is_unhelpful(rag_ans):
                        answer = add_disclaimer(rag_ans.strip())
                        sources_used = [{"rag": "general"}]
                    else:
                        free = qa_free_answer(q)
                        if free:
                            answer = add_disclaimer(free)
                            sources_used = [{"qa": "free"}]
                        else:
                            answer = add_disclaimer(
                                "ç›®å‰ç„¡æ³•ç›´æ¥å¾è³‡æ–™ä¸­æŸ¥åˆ°ç²¾æº–ç­”æ¡ˆï¼›"
                                "ä½ å¯ä»¥è£œå……åœ‹é“è™Ÿã€æ–¹å‘èˆ‡é‡Œç¨‹æˆ–æœå‹™å€åç¨±ï¼Œæˆ‘å†å¹«ä½ æŸ¥ã€‚"
                            )
                            sources_used = []
                    return

                else:
                    # å…¶å®ƒä¸é æœŸçš„ routeï¼šä¿éšª â†’ RAG + è»Ÿæ€§èªªæ˜
                    rag_ans = rag_answer(q)
                    if rag_ans and not _rag_is_unhelpful(rag_ans):
                        answer = add_disclaimer(rag_ans.strip())
                        sources_used = [{"rag": "refuse"}]
                    else:
                        answer = add_disclaimer(SOFT_REFUSAL)
                        sources_used = []
                    return

            except Exception:
                logging.error(f"[{req_id}] åˆ†æ”¯åŸ·è¡ŒéŒ¯èª¤ route={route}\n{traceback.format_exc()}")
                raise

        remain = max(0.1, SLA_SEC - (time.perf_counter() - t0) - 0.2)
        logging.debug(f"[{req_id}] SLA remainâ‰ˆ{remain:.2f}s")

        # é€™è£¡ä¸å†åš parallel_faqï¼Œå–®ç´”è·‘ä¸»è·¯ç”±é‚è¼¯
        await asyncio.wait_for(_do_main_route(), timeout=remain)

        # === API / QA æµç¨‹è·‘å®Œï¼Œéƒ½æœƒåˆ°é€™è£¡ä¾† ===
        if not answer:
            logging.warning(f"[{req_id}] ç„¡ç­”æ¡ˆâ†’å›è»Ÿæ€§èªªæ˜")
            answer = add_disclaimer(SOFT_REFUSAL)

        # 3) å¯« DBï¼ˆä¸ä¸­æ–·ï¼‰
        try:
            DB_CONFIG = {
                "host": os.getenv("DB_HOST", "").strip(),
                "user": os.getenv("DB_USER", "").strip(),
                "password": os.getenv("DB_PASSWORD", "").strip(),
                "database": os.getenv("DB_NAME", "").strip(),
                "port": int(os.getenv("DB_PORT", 3306)),
                "charset": "utf8mb4"
            }
            if _db_ready(DB_CONFIG):
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cursor:
                    sql = "INSERT INTO chat_history (ip_address, device_info, sender, message, created_at) VALUES (%s,%s,%s,%s,%s)"
                    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    cursor.execute(sql, (user_ip, user_agent, "user", q[:1000], now))
                    cursor.execute(sql, (user_ip, user_agent, "bot", (answer[:1000] if answer else "[NO_ANSWER]"), now))
                conn.commit()
                conn.close()
            else:
                logging.debug(f"[{req_id}] è·³éå¯«DBï¼ˆæœªé…ç½®ï¼‰")
        except Exception:
            logging.error(f"[{req_id}] å¯« DB å¤±æ•—\n{traceback.format_exc()}")

        # ===== å›å‚³é™¤éŒ¯è³‡è¨Šï¼ˆF12 å¯è¦‹ï¼‰=====
        timings_ms = ms_since(t0)
        debug = {
            "route": route,
            "filters": filters,
            "reason": reason,
            "forced_qa": forced_qa,
            "fallback": fallback_reason,
            "timings_ms": timings_ms,
            "confidence": round(confidence, 2),
            "sources": sources_used,
            "req_id": req_id,
        }
        # logging.info(f"[{req_id}] å®Œæˆ in {timings_ms} ms | route={route} conf={confidence:.2f} | sources={sources_used}")

        # Response Headersï¼ˆå« Trace IDï¼‰
        try:
            response.headers["X-Route"] = _latin1_safe(route)
            response.headers["X-Filters"] = _latin1_safe(json.dumps(filters, ensure_ascii=False))
            response.headers["X-Reason"] = _latin1_safe(reason)
            response.headers["X-Forced-QA"] = "true" if forced_qa else "false"
            response.headers["X-Fallback"] = _latin1_safe(fallback_reason or "")
            response.headers["X-Timings-ms"] = str(timings_ms)
            response.headers["X-Confidence"] = f"{confidence:.2f}"
            response.headers["X-Trace-Id"] = req_id
        except Exception:
            logging.error(f"[{req_id}] è¨­å®šå›æ‡‰æ¨™é ­å¤±æ•—\n{traceback.format_exc()}")

        return {"answer": answer, "route": route, "filters": filters, "reason": reason, "debug": debug}

    except asyncio.TimeoutError:
        logging.error(f"[{req_id}] å…¨åŸŸé€¾æ™‚ï¼ˆSLA={SLA_SEC}sï¼‰")
        return {
            "answer": add_disclaimer("ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"),
            "debug": {"error": "timeout", "req_id": req_id}
        }
    except Exception:
        logging.error(f"[{req_id}] å…¨åŸŸä¾‹å¤–\n{traceback.format_exc()}")
        return {
            "answer": add_disclaimer("æŸ¥è©¢å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"),
            "debug": {"error": "exception", "req_id": req_id}
        }

@app.get("/health")
def health():
    import time
    ok_key = bool(os.getenv("OPENAI_API_KEY", "").strip())
    key_mask = (os.getenv("OPENAI_API_KEY","").strip()[:7] + "â€¦") if ok_key else ""
    faq_idx = os.path.exists(os.path.join(os.getenv("FAQ_INDEX_DIR", os.path.join("faiss_index","faq_1968")), "index.faiss"))
    faq_json = os.path.exists(os.getenv("FAQ_JSON_PATH", os.path.join("PDF","1968_QA.json")))
    return {
        "time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "openai_key_present": ok_key,
        "openai_key_mask": key_mask,
        "faq_index_exists": faq_idx,
        "faq_json_exists": faq_json
    }

# =============================================================================
# å•Ÿå‹•
# =============================================================================
if __name__ == "__main__":
    uvicorn.run(
        app, host="0.0.0.0", port=8108,
        ssl_certfile="/app/IIS/59.126.242.4.pem",
        ssl_keyfile="/app/IIS/59.126.242.4.key"
    )
